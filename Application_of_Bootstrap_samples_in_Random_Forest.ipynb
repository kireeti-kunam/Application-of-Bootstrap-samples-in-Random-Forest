{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Application of Bootstrap samples in Random Forest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sNKZq4XrXQh"
      },
      "source": [
        "# <font color='red'><b>Bootstrap assignment</b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAHap1Z3FZC-"
      },
      "source": [
        "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
        "\n",
        "Every Grader function has to return True.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuxBq_bvrwh2"
      },
      "source": [
        "<font color='blue'> <b>Importing packages</b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6ag91ijrQOs"
      },
      "source": [
        "import numpy as np # importing numpy for numerical computation\n",
        "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
        "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from prettytable import PrettyTable"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcHOsONTt1K_"
      },
      "source": [
        "boston = load_boston()\n",
        "x=boston.data #independent variables\n",
        "y=boston.target #target variable"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc1htEFYuLRj",
        "outputId": "3281e1d0-19a9-470e-ba3d-8faf9b859191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x.shape,y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506, 13) (506,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEa_HqRZloH4"
      },
      "source": [
        "## <font color='red'><b>Task 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ5q8IxHNRk3"
      },
      "source": [
        "<font color='red'> <b>Step - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJCFCaOzl7Mr"
      },
      "source": [
        "*  <font color='blue'><b>Creating samples</b></font><br>\n",
        "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
        "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
        "    \n",
        "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
        "* <font color='blue'><b> Create 30 samples </b></font>\n",
        "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
        "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
        "Make sure each sample will have atleast 3 feautres/columns/attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKuG2jEwchn6"
      },
      "source": [
        "def create_sample(data,y):\n",
        "  indexes_303  = np.random.choice(data.shape[0],size = 303,replace=False)  # taking 303 indices randomly\n",
        "  oob_indicies = [i for i in range(data.shape[0]) if i not in indexes_303] # taking out of bag points\n",
        "  indexes_203  = np.random.choice(indexes_303.shape[0],size = 203)         # taking 203 indices from random 303 indices\n",
        "  feature_indices = np.random.choice(data.shape[1],size =3,replace=False)  # taking any 3 feature indexes randomly\n",
        "\n",
        "  sample       =  np.append(data[indexes_303,:],data[indexes_203,:],axis=0)\n",
        "  sample       =  sample[:,feature_indices]\n",
        "  \n",
        "  target       =  np.append(y[indexes_303],y[indexes_203],axis=0)\n",
        "\n",
        "\n",
        "  return sample,target,oob_indicies,feature_indices"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUqFEBSvNjCa"
      },
      "source": [
        "<font color='red'><b>Step - 2 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqi9AhCYNq3Z"
      },
      "source": [
        "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lLBnZHXOFln"
      },
      "source": [
        "*  Build a regression trees on each of 30 samples.\n",
        "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
        "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTuLqeeQch0Q"
      },
      "source": [
        "y_pred  = np.zeros((30,506))\n",
        "for_oob = np.zeros((30,506))\n",
        "trees = []\n",
        "features_per_tree = []\n",
        "\n",
        "for i in range(30):\n",
        "\n",
        "  sample,target,oob,fi = create_sample(x,y)\n",
        "\n",
        "  features_per_tree.append(fi) \n",
        "\n",
        "  regressor = DecisionTreeRegressor(max_depth=None)\n",
        "  regressor.fit(sample,target)\n",
        "\n",
        "  y_pred[i,:] = regressor.predict(x[:,fi])\n",
        "\n",
        "  oob_points = x[oob,:]\n",
        "  oob_points = oob_points[:,fi]\n",
        "\n",
        "\n",
        "  for_oob[i,oob] = regressor.predict(oob_points)\n",
        "\n",
        "  trees.append(regressor)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luo91xOzovqI"
      },
      "source": [
        "*  <font color='blue'><b>Calculating the MSE score </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PghK-6UjAC5-",
        "outputId": "9e4dd5af-f0e8-416d-a083-9c6551254700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred = (y_pred.sum(axis=0))/30\n",
        "mse = (((y-y_pred)**2).sum(axis=0))/506\n",
        "\n",
        "print(\"Mean squared error is: \",mse)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error is:  3.8146387368896915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kls23JLnSN23"
      },
      "source": [
        "<font color='red'> <b>Step - 3 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz2GchkGSWnh"
      },
      "source": [
        "*  <font color='blue'><b>Calculating the OOB score </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGHkVV2kSibm"
      },
      "source": [
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was built on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
        "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUx9VF5foN4d",
        "outputId": "e570f127-54c6-4257-8110-392baa7bc2a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "k_s = np.count_nonzero(for_oob,axis=0)\n",
        "oob_pred = (for_oob.sum(axis=0))/k_s\n",
        "oob_score = (((oob_pred-y_pred)**2).sum(axis=0))/506\n",
        "print(\"Out of bag score is: \",oob_score)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Out of bag score is:  5.692529569729782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK860ocxTyoz"
      },
      "source": [
        "# <font color='red'><b>Task 2</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dme-N6TUCrY"
      },
      "source": [
        "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
        "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
        "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
        "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
        "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
        "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJUbWbKZOojZ"
      },
      "source": [
        "def confidence_interval(features,targets):\n",
        "\n",
        "  x = features\n",
        "  y = targets\n",
        "\n",
        "  mse_scores = []\n",
        "  oob_scores = []\n",
        "\n",
        "  for i in range(35):\n",
        "    y_pred  = np.zeros((30,506))\n",
        "    for_oob = np.zeros((30,506))\n",
        "    trees = []\n",
        "    features_per_tree = []\n",
        "\n",
        "    for i in range(30):\n",
        "\n",
        "      sample,target,oob,fi = create_sample(x,y)\n",
        "\n",
        "      features_per_tree.append(fi) \n",
        "\n",
        "      regressor = DecisionTreeRegressor(max_depth=None)\n",
        "      regressor.fit(sample,target)\n",
        "\n",
        "      y_pred[i,:] = regressor.predict(x[:,fi])\n",
        "\n",
        "      oob_points = x[oob,:]\n",
        "      oob_points = oob_points[:,fi]\n",
        "\n",
        "\n",
        "      for_oob[i,oob] = regressor.predict(oob_points)\n",
        "\n",
        "      trees.append(regressor)\n",
        "    \n",
        "    y_pred = (y_pred.sum(axis=0))/30\n",
        "    mse = (((y-y_pred)**2).sum(axis=0))/506\n",
        "\n",
        "    k_s = np.count_nonzero(for_oob,axis=0)\n",
        "    oob_pred = (for_oob.sum(axis=0))/k_s\n",
        "    oob_score = (((oob_pred-y_pred)**2).sum(axis=0))/506\n",
        "\n",
        "    mse_scores.append(mse)\n",
        "    oob_scores.append(oob_score)\n",
        "  \n",
        "  return mse_scores,oob_scores\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkqvqlz1Oo_w"
      },
      "source": [
        "mse_scores,oob_scores = confidence_interval(x,y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnsZ0aZH6WM6"
      },
      "source": [
        "*  <font color='blue'><b>Computing CI (Background Theory)</b></font>\n",
        "  *   First we will answer this question. What is meant by 95% confidence interval ? </li>\n",
        "   - <b> 95% confidence interval does not eaxctly means that 95% of data lies in the gievn boundary. The exact meaning of that is if you are performing an experiment of taking samples from population and each sample have finite no.of observations and your keep on taking samples. Now 95% of times your population mean will fall in the confidence intervals calculated using the samples</b>.\n",
        "<li> To calculate the confidence interval of population mean we have some methods. </li>\n",
        "<li> Here we are assuming that we don't know the population standard deviation, \n",
        "now we will take the sample with finite no.of observations from the population and we will calculate the mean and standard deviation of the sample and we will assume the standard deviation of the population is same as the standard deviation of sample. So now the standard deviation of sample  = (standard deviation of sample)/sqrt(n). \n",
        "where n = no. of observations in the sample.  </li>\n",
        "<li> 95% confidence interval = [sample_mean-2*standard deviation of sample ,  sample_mean+2*standard deviation of sample] </li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlL3ENA728V3"
      },
      "source": [
        " - <font color='blue'><b>95% confidence interval for population mean of MSE</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldMRKvAKOo0E",
        "outputId": "8d4aecab-a0e6-40a8-953c-34194d68cba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "mse_scores = np.asarray(mse_scores)\n",
        "x = PrettyTable()\n",
        "x = PrettyTable([\"#samples\", \"Sample Size\", \"Sample mean\", \"Sample std\", \"Population mean\",\"Left C.I\",\"Right C.I\",\"Catch\"])\n",
        "\n",
        "Population_mean = mse_scores.mean()\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "    sample = mse_scores[np.random.choice(mse_scores.shape[0],size = 20)]\n",
        "    sample_size = len(sample)\n",
        "    sample_mean = sample.mean()\n",
        "    sample_std =  sample.std()\n",
        "\n",
        "    # here we are using sample standard deviation instead of population standard deviation\n",
        "    left_limit  = np.round(sample_mean - 2*(sample_std/np.sqrt(sample_size)), 3)\n",
        "    right_limit = np.round(sample_mean + 2*(sample_std/np.sqrt(sample_size)), 3)\n",
        "\n",
        "    row = []\n",
        "    row.append(i+1)\n",
        "    row.append(sample_size)\n",
        "    row.append(sample_mean)\n",
        "    row.append(sample_std)\n",
        "    row.append(Population_mean)\n",
        "    row.append(left_limit)\n",
        "    row.append(right_limit)\n",
        "    row.append((Population_mean <= right_limit) and (Population_mean >= left_limit))\n",
        "    x.add_row(row)\n",
        "print(x)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------+--------------------+--------------------+--------------------+----------+-----------+-------+\n",
            "| #samples | Sample Size |    Sample mean     |     Sample std     |  Population mean   | Left C.I | Right C.I | Catch |\n",
            "+----------+-------------+--------------------+--------------------+--------------------+----------+-----------+-------+\n",
            "|    1     |      20     | 3.816616485836852  | 0.7996984170951091 | 4.1679015745287655 |  3.459   |   4.174   |  True |\n",
            "|    2     |      20     | 4.049385947354119  | 0.774344078882585  | 4.1679015745287655 |  3.703   |   4.396   |  True |\n",
            "|    3     |      20     | 3.6688417776465676 | 0.7697917714625971 | 4.1679015745287655 |  3.325   |   4.013   | False |\n",
            "|    4     |      20     | 4.238493021343574  | 0.7805344934932933 | 4.1679015745287655 |  3.889   |   4.588   |  True |\n",
            "|    5     |      20     | 4.457841497977688  |  0.93942477245271  | 4.1679015745287655 |  4.038   |   4.878   |  True |\n",
            "|    6     |      20     | 4.171973109819514  | 0.7837472241396597 | 4.1679015745287655 |  3.821   |   4.522   |  True |\n",
            "|    7     |      20     | 4.380861224564541  | 0.7902548644871884 | 4.1679015745287655 |  4.027   |   4.734   |  True |\n",
            "|    8     |      20     | 4.126500395094274  | 1.019263017749317  | 4.1679015745287655 |  3.671   |   4.582   |  True |\n",
            "|    9     |      20     | 3.924116372261684  | 0.9201235900498812 | 4.1679015745287655 |  3.513   |   4.336   |  True |\n",
            "|    10    |      20     | 4.212964970032534  | 0.9908044972443285 | 4.1679015745287655 |   3.77   |   4.656   |  True |\n",
            "+----------+-------------+--------------------+--------------------+--------------------+----------+-----------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZBnphxw3YNM"
      },
      "source": [
        " - <font color='blue'><b>95% Confidence interval for population mean of OOB Score</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km-WSQJvOlHL",
        "outputId": "eb14966f-c5a9-4e6d-a448-df2c45755a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "oob_scores = np.asarray(oob_scores)\n",
        "x = PrettyTable()\n",
        "x = PrettyTable([\"#samples\", \"Sample Size\", \"Sample mean\", \"Sample std\", \"Population mean\",\"Left C.I\",\"Right C.I\",\"Catch\"])\n",
        "\n",
        "Population_mean = oob_scores.mean()\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "    sample = oob_scores[np.random.choice(oob_scores.shape[0],size = 20)]\n",
        "    sample_size = len(sample)\n",
        "    sample_mean = sample.mean()\n",
        "    sample_std =  sample.std()\n",
        "\n",
        "    # here we are using sample standard deviation instead of population standard deviation\n",
        "    left_limit  = np.round(sample_mean - 2*(sample_std/np.sqrt(sample_size)), 3)\n",
        "    right_limit = np.round(sample_mean + 2*(sample_std/np.sqrt(sample_size)), 3)\n",
        "\n",
        "    row = []\n",
        "    row.append(i+1)\n",
        "    row.append(sample_size)\n",
        "    row.append(sample_mean)\n",
        "    row.append(sample_std)\n",
        "    row.append(Population_mean)\n",
        "    row.append(left_limit)\n",
        "    row.append(right_limit)\n",
        "    row.append((Population_mean <= right_limit) and (Population_mean >= left_limit))\n",
        "    x.add_row(row)\n",
        "print(x)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------+--------------------+--------------------+-------------------+----------+-----------+-------+\n",
            "| #samples | Sample Size |    Sample mean     |     Sample std     |  Population mean  | Left C.I | Right C.I | Catch |\n",
            "+----------+-------------+--------------------+--------------------+-------------------+----------+-----------+-------+\n",
            "|    1     |      20     | 4.6841165191110665 | 0.8144850564367405 | 4.657297351316141 |   4.32   |   5.048   |  True |\n",
            "|    2     |      20     | 4.660548067579326  | 0.6532932760543365 | 4.657297351316141 |  4.368   |   4.953   |  True |\n",
            "|    3     |      20     | 4.550747820961018  | 0.7489167247742978 | 4.657297351316141 |  4.216   |   4.886   |  True |\n",
            "|    4     |      20     | 4.793247739063346  | 0.5938873341917454 | 4.657297351316141 |  4.528   |   5.059   |  True |\n",
            "|    5     |      20     | 4.537841375037493  | 0.8053855638969996 | 4.657297351316141 |  4.178   |   4.898   |  True |\n",
            "|    6     |      20     | 4.7808300169354165 | 0.5767791162520431 | 4.657297351316141 |  4.523   |   5.039   |  True |\n",
            "|    7     |      20     | 4.557958915239024  | 0.6386884814057943 | 4.657297351316141 |  4.272   |   4.844   |  True |\n",
            "|    8     |      20     | 4.928565996512878  | 0.7156965627246081 | 4.657297351316141 |  4.608   |   5.249   |  True |\n",
            "|    9     |      20     | 4.7096081355022275 | 0.6933034065695328 | 4.657297351316141 |   4.4    |    5.02   |  True |\n",
            "|    10    |      20     | 4.571316926603492  | 0.8114448529649804 | 4.657297351316141 |  4.208   |   4.934   |  True |\n",
            "+----------+-------------+--------------------+--------------------+-------------------+----------+-----------+-------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6UcH1x9Uwrj"
      },
      "source": [
        "# <font color='red'><b>Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOC_AgsLU7OH"
      },
      "source": [
        "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYs5jSFdVILe"
      },
      "source": [
        "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
        "Predict the house price for this point as mentioned in the step 2 of Task 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uLlR6OHrrJq",
        "outputId": "18c85e31-5daa-4a3c-bd46-d0209b4fe40f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "xq= np.array([0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60])\n",
        "\n",
        "predicted_value = 0\n",
        "\n",
        "for model in range(30):\n",
        "   predicted_value+=trees[i].predict(xq[features_per_tree[model]].reshape(1,-1))\n",
        "\n",
        "print(\"The predicted output(House price) for the given query point is \",predicted_value/30)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted output(House price) for the given query point is  [20.35666667]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6gxZEsFWm-8"
      },
      "source": [
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJHTGEZgWJjR"
      },
      "source": [
        "<br><br><br>"
      ]
    }
  ]
}